<<<<<<< HEAD
# ðŸ“Š Loan RAG Q&A Chatbot

This is an interactive chatbot that uses **RAG (Retrieval-Augmented Generation)** to intelligently answer user questions from a **Loan CSV dataset**. It combines local **LLMs (like Mistral 7B)** with **LangChain**, **FAISS vector store**, and **Streamlit** to provide insightful, document-based answers.

---

## ðŸ’¡ Features

- ðŸ’¬ Ask questions from a loan dataset in natural language.
- ðŸ” Retrieves relevant chunks using **FAISS** vector store.
- ðŸ§  Generates context-aware responses using **Llama.cpp-powered Mistral 7B** model.
- ðŸ“œ Maintains chat history in session.
- ðŸ“ Fully local, privacy-respecting architecture.
- ðŸŽ¨ Clean and informative **Streamlit UI**.

---

## ðŸ› ï¸ Tech Stack

| Technology             | Usage                        |
|------------------------|------------------------------|
| Python                 | Backend logic                |
| Streamlit              | Frontend UI                  |
| LangChain              | RAG orchestration            |
| LlamaCpp               | Local LLM inference engine   |
| FAISS                  | Vector store for retrieval   |
| HuggingFace Embeddings | Sentence embedding           |
| dotenv                 | Secure config loading        |

---

## ðŸ“‚ Folder Structure

```bash
.
â”œâ”€â”€ app.py                    # Streamlit frontend
â”œâ”€â”€ rag_chatbot.py           # RAG logic using LangChain
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Training Dataset.csv.xls
â”œâ”€â”€ .env                     # Model path and secrets
â””â”€â”€ requirements.txt         # Python dependencies
```
---

## âš™ï¸ Setup Instructions

1. **Clone the repository**:

```bash
git clone https://github.com/Vanij-Prasher/Loan-RAG-Bot.git
cd Loan-RAG-Bot
```
2.	**Install dependencies**:
```bash
pip install -r requirements.txt
```
3.	**Download and setup your local model (e.g., Mistral-7B) and update the .env**:
```bash
MODEL_PATH=/absolute/path/to/your/mistral-7b.Q4_K_M.gguf
```
4.	**Run the chatbot**:
```bash
streamlit run app.py
```
### ðŸ™‹â€â™‚ï¸ **About the Developer**

**Vanij Prasher**
ðŸ‘¨â€ðŸ’» Data Science Intern at Celebal Technologies
ðŸ’¡ Passionate about AI, LLMs,Data Science and Real-world Applications
ðŸ“« GitHub- https://github.com/Vanij-Prasher | LinkedIn- https://www.linkedin.com/in/vanij-prasher/

---

## ðŸ“¸ Screenshots

### ðŸ”¹ Homepage UI
![UI Screenshot](Screenshorts/Homepage.png)

### ðŸ”¹ Basic UI
![Basic UI](Screenshorts/Basic-UI.png)

### ðŸ”¹ Answer
![Answer ](Screenshorts/Answer.png)

### ðŸ”¹ Chat History
![Chat History](Screenshorts/Chat-History.png)
=======
# ðŸš€ Celebal Tech Data Science Internship Portfolio â€“ Vanij Prasher

Welcome to my internship repository for Celebal Technologies (Summer 2025), where I explored and implemented various **Data Science**, **Machine Learning**, and **Deployment** concepts. This repository reflects my weekly progress, hands-on projects, and real-world implementation of data-centric solutions.

---

## ðŸ™‹â€â™‚ï¸ About Me

I am **Vanij Prasher**, a passionate Data Science enthusiast with a strong inclination towards building **end-to-end data-driven applications**. During this internship, I focused on:
- Strengthening my understanding of machine learning workflows
- Performing deep data analysis and model optimization
- Learning deployment techniques using **Streamlit**

ðŸ”— [LinkedIn](https://www.linkedin.com/in/vanij-prasher) â€¢ ðŸ“« [2004vanij.prasher@gmail.com](mailto:vanijprasher@gmail.com)

---

## ðŸ¢ About Celebal Technologies

**Celebal Technologies** is a premier AI and Big Data company that provides cutting-edge solutions to global enterprises. This internship helped me:
- Apply theoretical knowledge to practical problems
- Learn software development best practices
- Work on real-world data science workflows

---

# ðŸ› ï¸ Skills Acquired During the Celebal Tech Internship

Throughout the internship, I worked on a series of weekly projects that helped me build and sharpen my skills across multiple domains in Data Science, Machine Learning, and Deployment. Here's a summary of the skills I acquired:

---

## ðŸ‘¨â€ðŸ’» Python Programming
- Writing clean, readable, and modular Python code
- Applying Object-Oriented Programming (OOP) concepts
- Handling files and exceptions efficiently

---

## ðŸ“Š Data Analysis & Visualization
- Performing Exploratory Data Analysis (EDA) using:
  - `pandas` for data manipulation
  - `matplotlib` and `seaborn` for visualizations
- Creating insightful charts such as:
  - Histograms, boxplots, scatter plots, heatmaps
- Understanding distributions, correlations, and data patterns

---

## ðŸ¤– Machine Learning
- Implementing supervised learning models including:
  - Random Forest, Logistic Regression, and Support Vector Machines (SVM)
- Evaluating model performance using:
  - Accuracy, Precision, Recall, F1-Score
- Splitting datasets and managing training/testing workflow

---

## ðŸ§  Model Optimization
- Tuning hyperparameters using:
  - `GridSearchCV`
  - `RandomizedSearchCV`
- Comparing model scores to select the best-performing model

---

## ðŸŒ Model Deployment
- Deploying Machine Learning models using **Streamlit**
- Creating interactive UI for predictions
- Saving and loading trained models with `joblib`
- Designing a complete ML web app

---

## ðŸ“ Project & Code Management
- Organizing weekly assignments into structured folders
- Writing reusable functions and clean scripts
- Following good naming conventions and commenting practices

---

## ðŸŒ€ Version Control (Git & GitHub)
- Initializing and managing Git repositories
- Committing, pushing, and managing branches
- Handling merge conflicts and restoring deleted work

---

## ðŸ“ Documentation & Communication
- Writing detailed and professional `README.md` files
- Documenting objectives, methodologies, and outcomes
- Using markdown effectively to improve project presentation

---

> âœ… These skills reflect my hands-on experience across the full **Data Science Lifecycle** â€” from raw data to deployed application.

## ðŸ“ Repository Structure

Each week includes a focused project or task with accompanying code and documentation.
```
Celebal-Tech-Vanij/
â”œâ”€â”€ week1                           # Triangle Pattern Printing
â”œâ”€â”€ week2                           # Singly Linked List with OOP
â”œâ”€â”€ week3                           # Titanic Dataset Visualizations
â”œâ”€â”€ week4                           # Titanic Dataset EDA
â”œâ”€â”€ week5                           # House Price Prediction Model
â”œâ”€â”€ week6                           # Model Evaluation & Hyperparameter Tuning
â”œâ”€â”€ week7                           # Iris Classifier Streamlit App
â”œâ”€â”€ README.md                       # General Overview (This file)
```
---

## ðŸ“š Weekly Task Overview

| Week | Task Title                                       | Focus Area                                      |
|------|--------------------------------------------------|--------------------------------------------------|
| 1ï¸âƒ£  | Pattern Printing                                  | Python Basics, Control Structures               |
| 2ï¸âƒ£  | Singly Linked List                                | Object-Oriented Programming (OOP)               |
| 3ï¸âƒ£  | Data Visualization (Titanic Dataset)              | Seaborn, Matplotlib, EDA                        |
| 4ï¸âƒ£  | Exploratory Data Analysis (Titanic)               | Correlation, Null Handling, Boxplots, Heatmaps  |
| 5ï¸âƒ£  | House Price Prediction                            | Feature Engineering, Regression, Random Forest  |
| 6ï¸âƒ£  | Model Evaluation & Tuning                         | Metrics, GridSearchCV, RandomizedSearchCV       |
| 7ï¸âƒ£  | Streamlit ML App â€“ Iris Flower Predictor.         | Deployment, Streamlit, UI/UX, Joblib            |

Each week's code includes a `README.md` with explanations, sample outputs, and methodology used.

---

## ðŸ§  Skills Demonstrated

- ðŸ Python (OOP, File Handling, Control Structures)
- ðŸ“Š Data Analysis with Pandas & NumPy
- ðŸ“ˆ Data Visualization with Seaborn & Matplotlib
- ðŸ¤– Machine Learning (Classification, Regression, Evaluation)
- ðŸŽ¯ Hyperparameter Tuning (GridSearchCV, RandomizedSearchCV)
- ðŸŒ Deployment using Streamlit
- ðŸ—‚ï¸ Code Structuring & Git Version Control

---

## ðŸ’¼ Key Takeaways

âœ… Practiced hands-on ML model building  
âœ… Performed real-world data cleaning and feature analysis  
âœ… Built a complete ML web app with live predictions  
âœ… Enhanced understanding of EDA and business insights  
âœ… Developed professional documentation and code workflow

---

## ðŸ¤ Acknowledgments

- Huge thanks to Celebal Tech mentors and internship coordinators for the opportunity and constant support ðŸ™Œ
- Special appreciation to peers and contributors for collaborative learning during this internship period

---

## ðŸ“¬ Contact

For queries, collaborations or internship insights:

- ðŸ“§ 2004vanij.prasher@gmail.com
- ðŸŒ [LinkedIn â€“ Vanij Prasher](https://www.linkedin.com/in/vanij-prasher)

---

Made with ðŸ’™ by Vanij Prasher | Celebal Technologies â€“ Data Science Internship 2025
>>>>>>> 5413da60c633b95ab5e8adcec34c778125499742
